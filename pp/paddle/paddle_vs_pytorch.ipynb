{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import paddle\n",
    "import collections\n",
    "import typing\n",
    "import json\n",
    "import itertools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu101\n",
      "2.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7604\n",
      "gpu:0\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(paddle.device.get_cudnn_version())\n",
    "print(paddle.device.get_device())\n",
    "\n",
    "data = torch.rand(2, 2)\n",
    "print(data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUPlace\n",
      "<class 'paddle.fluid.core_avx.CPUPlace'>\n",
      "Tensor(shape=[2, 2], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[0.72883028, 0.14966780],\n",
      "        [0.56501168, 0.48528844]])\n"
     ]
    }
   ],
   "source": [
    "device = paddle.set_device('cpu')\n",
    "print(device)\n",
    "print(type(device))\n",
    "\n",
    "data = paddle.rand(shape=(2, 2))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.Module.__repr__\n",
    "# def extra_repr(self) -> str:\n",
    "\n",
    "torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2, padding=1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<paddle.nn.layer.conv.Conv2D at 0x1f943e33a68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None\n",
    "paddle.nn.Conv2D(3, 32, kernel_size=(3, 2), stride=2, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MM(\n",
       "  (f1): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (seq1): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (1): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (seq2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (1): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MM(torch.nn.Module):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, ):\n",
    "        super(MM, self).__init__()\n",
    "        \n",
    "        self.f1 = torch.nn.Linear(10, 10)\n",
    "        self.conv1 = torch.nn.Conv2d(3, 10, 3, 2)\n",
    "        self.seq1 = torch.nn.Sequential(torch.nn.Linear(10, 10), torch.nn.Conv2d(3, 10, 3, 2)) \n",
    "        self.seq2 = torch.nn.Sequential(self.seq1, torch.nn.Conv2d(3, 10, 3, 2))\n",
    "    def forward(self, ):\n",
    "        '''\n",
    "        '''\n",
    "        pass\n",
    "MM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MM at 0x1f943e33fa8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MM(paddle.nn.Layer):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, ):\n",
    "        super(MM, self).__init__()\n",
    "        \n",
    "        self.f1 = paddle.nn.Linear(10, 10)\n",
    "        self.conv1 = paddle.nn.Conv2D(3, 10, 3, 2)\n",
    "        self.relu = paddle.nn.ReLU()\n",
    "        self.seq1 = paddle.nn.Sequential(paddle.nn.Linear(10, 10), paddle.nn.Conv2D(3, 10, 3, 2)) \n",
    "        \n",
    "    def forward(self, ):\n",
    "        '''\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "MM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_name(layer:paddle.nn.Layer) -> str:\n",
    "    ''''''\n",
    "    return layer.__class__.__name__\n",
    "\n",
    "\n",
    "def repr_string(layer:paddle.nn.Layer) -> str:\n",
    "    ''''''\n",
    "    s = collections.OrderedDict()\n",
    "\n",
    "    if isinstance(layer, paddle.nn.Conv2D):\n",
    "        _s = ''\n",
    "        _s += f'{layer._in_channels}, {layer._out_channels}, '\n",
    "        _s += f'kernel_size={tuple(layer._kernel_size)}, stride={tuple(layer._stride)}, '\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    elif isinstance(layer, paddle.nn.Linear):\n",
    "        _s = ''\n",
    "        _s += f'input_dim={layer.weight.shape[0]}, output_dim={layer.weight.shape[1]}'\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    elif isinstance(layer, paddle.nn.Dropout):\n",
    "        _s = ''\n",
    "        _s += f'p={layer.p}'\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    elif isinstance(layer, paddle.nn.ReLU):\n",
    "        _s = ''\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    elif _get_name(layer) in set(dir(paddle.nn)).difference(set(['Layer', 'Sequential', 'LayerList', 'ParameterList'])):\n",
    "        _s = ''\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    for _name, _layer in layer.named_children():\n",
    "        _s = _name\n",
    "        if isinstance(_layer, (paddle.nn.Sequential, paddle.nn.LayerList, paddle.nn.ParameterList)):\n",
    "            _s += f' ({_get_name(_layer)})'\n",
    "            \n",
    "        s.update({_s: repr_string(_layer)})\n",
    "    \n",
    "    # return {f'{_get_name(layer)}': s}\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "   \"f1\": \"Linear(input_dim=10, output_dim=10)\",\n",
       "   \"conv1\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\",\n",
       "   \"relu\": \"ReLU()\",\n",
       "   \"seq1 (Sequential)\": {\n",
       "      \"0\": \"Linear(input_dim=10, output_dim=10)\",\n",
       "      \"1\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\"\n",
       "   },\n",
       "   \"seq2 (Sequential)\": {\n",
       "      \"0 (Sequential)\": {\n",
       "         \"0\": \"Linear(input_dim=10, output_dim=10)\",\n",
       "         \"1\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\"\n",
       "      },\n",
       "      \"1\": \"Linear(input_dim=10, output_dim=10)\",\n",
       "      \"2\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\"\n",
       "   },\n",
       "   \"conv2\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\",\n",
       "   \"mlist (LayerList)\": {\n",
       "      \"0\": \"Linear(input_dim=10, output_dim=10)\",\n",
       "      \"1\": \"Linear(input_dim=10, output_dim=10)\",\n",
       "      \"2\": \"Linear(input_dim=10, output_dim=10)\"\n",
       "   },\n",
       "   \"dropout\": \"Dropout(p=0.5)\"\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "class MM(paddle.nn.Layer):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, ):\n",
    "        super(MM, self).__init__()\n",
    "        \n",
    "        self.f1 = paddle.nn.Linear(10, 10)\n",
    "        self.conv1 = paddle.nn.Conv2D(3, 10, 3, 2)\n",
    "        self.relu = paddle.nn.ReLU()\n",
    "        self.seq1 = paddle.nn.Sequential(paddle.nn.Linear(10, 10), paddle.nn.Conv2D(3, 10, 3, 2)) \n",
    "        self.seq2 = paddle.nn.Sequential(self.seq1, paddle.nn.Linear(10, 10), paddle.nn.Conv2D(3, 10, 3, 2))\n",
    "        self.conv2 = paddle.nn.Conv2D(3, 10, 3, 2)\n",
    "        self.mlist = paddle.nn.LayerList([paddle.nn.Linear(10, 10) for i in range(3)])\n",
    "        self.dropout = paddle.nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, ):\n",
    "        '''\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def __repr__(self,):\n",
    "        ''''''\n",
    "        # s = repr_string(self)\n",
    "        return json.dumps(repr_string(self), indent=3)\n",
    "    \n",
    "MM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(f1): Linear(input_dim=10, output_dim=10)\n",
      "(conv1): Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      "(relu): \n",
      "(seq1):Sequential\n",
      "(\n",
      "(0): Linear(input_dim=10, output_dim=10)\n",
      "(1): Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      ")\n",
      "(seq2):Sequential\n",
      "(\n",
      "(0):Sequential\n",
      "(\n",
      "(0): Linear(input_dim=10, output_dim=10)\n",
      "(1): Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      ")\n",
      "(1): Linear(input_dim=10, output_dim=10)\n",
      "(2): Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      ")\n",
      "(conv2): Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      "(mlist): (0): Linear(input_dim=10, output_dim=10)\n",
      "(1): Linear(input_dim=10, output_dim=10)\n",
      "(2): Linear(input_dim=10, output_dim=10)\n",
      "(dropout): \n"
     ]
    }
   ],
   "source": [
    "mm = MM()\n",
    "\n",
    "def _get_name(layer:paddle.nn.Layer) -> str:\n",
    "    ''''''\n",
    "    return layer.__class__.__name__\n",
    "\n",
    "\n",
    "def repr_string(layer:paddle.nn.Layer) -> str:\n",
    "    ''''''\n",
    "    s = []\n",
    "    \n",
    "    if isinstance(layer, paddle.nn.Conv2D):\n",
    "        _s = ''\n",
    "        _s += f'{layer._in_channels}, {layer._out_channels}, '\n",
    "        _s += f'kernel_size={tuple(layer._kernel_size)}, stride={tuple(layer._stride)}'\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    if isinstance(layer, paddle.nn.Linear):\n",
    "        _s = ''\n",
    "        _s += f'input_dim={layer.weight.shape[0]}, output_dim={layer.weight.shape[1]}'\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "        \n",
    "    for _name, _layer in layer.named_children():\n",
    "        if isinstance(_layer, paddle.nn.Sequential):\n",
    "            _s = '({}):Sequential\\n'.format(_name)\n",
    "            _s += '(\\n{}\\n)'.format(repr_string(_layer))\n",
    "            s.append(_s)  \n",
    "        else:\n",
    "            _s = '({}): '.format(_name)\n",
    "            _s += repr_string(_layer)\n",
    "            s.append(_s)\n",
    "\n",
    "    return '\\n'.join(s)\n",
    "\n",
    "print(repr_string(mm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MM(\n",
       "  (f1): Linear(input_dim=10, output_dim=10)\n",
       "  (conv1): Conv2D(3, 10, kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=[1, 1])\n",
       "  (relu): ReLU()\n",
       "  (seq1): Sequential(\n",
       "    (0): Linear(input_dim=10, output_dim=10)\n",
       "    (1): Conv2D(3, 10, kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=[1, 1])\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py\n",
    "# \n",
    "    \n",
    "def _addindent(s_, numSpaces):\n",
    "    '''\n",
    "    '''\n",
    "    s = s_.split('\\n')\n",
    "    # don't do anything for single-line stuff\n",
    "    if len(s) == 1:\n",
    "        return s_\n",
    "    first = s.pop(0)\n",
    "    s = [(numSpaces * ' ') + line for line in s]\n",
    "    s = '\\n'.join(s)\n",
    "    s = first + '\\n' + s\n",
    "    return s\n",
    "\n",
    "\n",
    "# TODO\n",
    "class Layer(paddle.nn.Layer):\n",
    "    def extra_repr(self) -> str:\n",
    "        r\"\"\"Set the extra representation of the module\n",
    "        To print customized extra information, you should re-implement\n",
    "        this method in your own modules. Both single-line and multi-line\n",
    "        strings are acceptable.\n",
    "        \"\"\"\n",
    "        return ''\n",
    "    \n",
    "    def _get_name(self):\n",
    "        '''\n",
    "        '''\n",
    "        return self.__class__.__name__\n",
    "    \n",
    "    def __repr__(self):\n",
    "        '''\n",
    "        '''\n",
    "        # We treat the extra repr like the sub-module, one item per line\n",
    "        extra_lines = []\n",
    "        extra_repr = self.extra_repr()\n",
    "        # empty string will be split into list ['']\n",
    "        if extra_repr:\n",
    "            extra_lines = extra_repr.split('\\n')\n",
    "        child_lines = []\n",
    "        for key, module in self._sub_layers.items():\n",
    "            mod_str = repr(module)\n",
    "            mod_str = _addindent(mod_str, 2)\n",
    "            child_lines.append('(' + key + '): ' + mod_str)\n",
    "        lines = extra_lines + child_lines\n",
    "\n",
    "        main_str = self._get_name() + '('\n",
    "        if lines:\n",
    "            # simple one-liner info, which most builtin Modules will use\n",
    "            if len(extra_lines) == 1 and not child_lines:\n",
    "                main_str += extra_lines[0]\n",
    "            else:\n",
    "                main_str += '\\n  ' + '\\n  '.join(lines) + '\\n'\n",
    "\n",
    "        main_str += ')'\n",
    "        return main_str\n",
    "\n",
    "\n",
    "class Conv2D(Layer, paddle.nn.layer.conv.Conv2D):\n",
    "    def extra_repr(self, ):\n",
    "        '''\n",
    "        '''\n",
    "        s = ('{_in_channels}, {_out_channels}, kernel_size={_kernel_size}'\n",
    "             ', stride={_stride}')\n",
    "        if self._padding != (0,) * len(self._padding):\n",
    "            s += ', padding={_padding}'\n",
    "        if self._dilation != (1,) * len(self._dilation):\n",
    "            s += ', dilation={_dilation}'\n",
    "        if self._groups != 1:\n",
    "            s += ', groups={_groups}'\n",
    "        if self._padding_mode != 'zeros':\n",
    "            s += ', padding_mode={_padding_mode}'\n",
    "            \n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    \n",
    "class Linear(Layer, paddle.nn.layer.Linear):\n",
    "    def extra_repr(self, ):\n",
    "        '''\n",
    "        '''\n",
    "        _s = ''\n",
    "        _s += f'input_dim={self.weight.shape[0]}, output_dim={self.weight.shape[1]}'\n",
    "        return _s\n",
    "    \n",
    "    \n",
    "class ReLU(Layer, paddle.nn.layer.ReLU):\n",
    "    '''\n",
    "    '''\n",
    "    def extra_repr(self, ):\n",
    "        '''\n",
    "        '''\n",
    "        return ''\n",
    "    \n",
    "    \n",
    "class Sequential(Layer, paddle.nn.Sequential):\n",
    "    '''\n",
    "    '''\n",
    "    def _get_item_by_idx(self, iterator, idx):\n",
    "        \"\"\"Get the idx-th item of the iterator\"\"\"\n",
    "        size = len(self)\n",
    "        idx = operator.index(idx)\n",
    "        if not -size <= idx < size:\n",
    "            raise IndexError('index {} is out of range'.format(idx))\n",
    "        idx %= size\n",
    "        return next(itertools.islice(iterator, idx, None))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            return self.__class__(*list(self._sub_layers.items())[idx])\n",
    "        else:\n",
    "            return self._get_item_by_idx(self._sub_layers.values(), idx)\n",
    "        \n",
    "    def __setitem__(self, idx: int, layer: paddle.nn.Layer) -> None:\n",
    "        key = self._get_item_by_idx(self._sub_layers.keys(), idx)\n",
    "        return setattr(self, key, layer)\n",
    "\n",
    "    \n",
    "    \n",
    "# TODO\n",
    "class MM(Layer, paddle.nn.Layer):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, ):\n",
    "        super(MM, self).__init__()\n",
    "        \n",
    "        self.f1 = Linear(10, 10)\n",
    "        self.conv1 = Conv2D(3, 10, 3, 2)\n",
    "        self.relu = ReLU()\n",
    "        self.seq1 = Sequential(Linear(10, 10), Conv2D(3, 10, 3, 2)) \n",
    "        \n",
    "    def forward(self, ):\n",
    "        '''\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "MM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issubclass(paddle.nn.Layer, paddle.framework.core.Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/dygraph/container.py\n",
    "# https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/dygraph/container.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mm = torch.nn.Sequential(torch.nn.Linear(3, 3), torch.nn.ReLU(), torch.nn.Linear(100, 100))\n",
    "print(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=100, out_features=100, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(mm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mm[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      ")\n",
      "OrderedDict([('0', Linear(in_features=3, out_features=3, bias=True)), ('1', ReLU()), ('2', Linear(in_features=100, out_features=100, bias=True))])\n"
     ]
    }
   ],
   "source": [
    "mm[-1] = torch.nn.Linear(100, 100)\n",
    "print(mm)\n",
    "print(mm._modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<paddle.fluid.dygraph.container.Sequential object at 0x000001F9640D95E8>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'-1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-372511b4197d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\dygraph\\container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '-1'"
     ]
    }
   ],
   "source": [
    "mm = paddle.nn.Sequential(paddle.nn.Linear(3, 3), paddle.nn.ReLU())\n",
    "print(mm)\n",
    "print(mm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'slice(None, -1, None)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7332e144359e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\dygraph\\container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'slice(None, -1, None)'"
     ]
    }
   ],
   "source": [
    "print(mm[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class Sequential(paddle.nn.Sequential):\n",
    "    '''\n",
    "    '''\n",
    "    def _get_item_by_idx(self, iterator, idx):\n",
    "        \"\"\"Get the idx-th item of the iterator\"\"\"\n",
    "        size = len(self)\n",
    "        idx = operator.index(idx)\n",
    "        if not -size <= idx < size:\n",
    "            raise IndexError('index {} is out of range'.format(idx))\n",
    "        idx %= size\n",
    "        return next(itertools.islice(iterator, idx, None))\n",
    "    \n",
    "    def __getitem__(self, idx: Union[slice, int, str]):\n",
    "        r'''get \n",
    "        mm is sequential instance\n",
    "        mm[1]\n",
    "        mm[-1]\n",
    "        mm[1:]\n",
    "        mm['L1']\n",
    "        '''\n",
    "        if isinstance(idx, str):\n",
    "            return self._sub_layers[idx]\n",
    "        elif isinstance(idx, slice):\n",
    "            return self.__class__(*list(self._sub_layers.items())[idx])\n",
    "        else:\n",
    "            return self._get_item_by_idx(self._sub_layers.values(), idx)\n",
    "        \n",
    "    def __setitem__(self, idx: Union[int, str], layer: paddle.nn.Layer) -> None:\n",
    "        r'''set\n",
    "        mm is sequential instance\n",
    "        mm[1] = `Layer Instance`\n",
    "        mm['L1'] = `Layer Instance`\n",
    "        '''\n",
    "        if isinstance(idx, str):\n",
    "            return setattr(self, str(idx), layer)\n",
    "        else:\n",
    "            key = self._get_item_by_idx(self._sub_layers.keys(), idx)\n",
    "            return setattr(self, key, layer)\n",
    "        \n",
    "    def __delitem__(self, idx: Union[slice, int, str]) -> None:\n",
    "        r'''del \n",
    "        mm is sequential instance\n",
    "        del mm[0]\n",
    "        del mm[-1]\n",
    "        del mm['2']\n",
    "        del mm[1:]\n",
    "        '''\n",
    "        if isinstance(idx, slice):\n",
    "            for key in list(self._sub_layers.keys())[idx]:\n",
    "                delattr(self, key)\n",
    "        elif isinstance(idx, int):\n",
    "            key = self._get_item_by_idx(self._sub_layers.keys(), idx)\n",
    "            delattr(self, key)\n",
    "        else:\n",
    "            delattr(self, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   },\n",
      "   \"3\": \"Conv2D(2, 2, kernel_size=(2, 2), stride=(2, 2), )\",\n",
      "   \"4\": \"Linear(input_dim=3, output_dim=3)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "mm = Sequential(paddle.nn.Linear(3, 3), \n",
    "                  paddle.nn.ReLU(), \n",
    "                  paddle.nn.Sequential(paddle.nn.Linear(3, 3), paddle.nn.ReLU()), \n",
    "                  paddle.nn.Conv2D(2, 2, 2, 2, 2),\n",
    "                  paddle.nn.Linear(3, 3))\n",
    "\n",
    "print(json.dumps(repr_string(mm), indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Linear(input_dim=3, output_dim=3)\"\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(repr_string(mm[-1]), indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   },\n",
      "   \"3\": \"Conv2D(2, 2, kernel_size=(2, 2), stride=(2, 2), )\",\n",
      "   \"4\": \"ReLU()\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "mm[-1] = paddle.nn.ReLU()\n",
    "print(json.dumps(repr_string(mm), indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(repr_string(mm[:-2]), indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   },\n",
      "   \"3\": \"Conv2D(2, 2, kernel_size=(2, 2), stride=(2, 2), )\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(repr_string(paddle.nn.Sequential(*list(mm.children())[:-1])), indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   },\n",
      "   \"3\": \"Conv2D(2, 2, kernel_size=(2, 2), stride=(2, 2), )\",\n",
      "   \"4\": \"ReLU()\"\n",
      "}\n",
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   },\n",
      "   \"3\": \"Linear(input_dim=100, output_dim=300)\",\n",
      "   \"4\": \"ReLU()\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(repr_string(mm), indent=3))\n",
    "mm['3'] = paddle.nn.Linear(100, 300)\n",
    "print(json.dumps(repr_string(mm), indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   },\n",
      "   \"3\": \"Linear(input_dim=100, output_dim=300)\"\n",
      "}\n",
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"3\": \"Linear(input_dim=100, output_dim=300)\"\n",
      "}\n",
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "del mm[-1]\n",
    "print(json.dumps(repr_string(mm), indent=3))\n",
    "\n",
    "del mm['2']\n",
    "print(json.dumps(repr_string(mm), indent=3))\n",
    "\n",
    "del mm[1:]\n",
    "print(json.dumps(repr_string(mm), indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModulList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mm = torch.nn.ModuleList([torch.nn.Linear(3, 3), torch.nn.ReLU()])\n",
    "print(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mm[-1] = torch.nn.Linear(10, 10)\n",
    "print(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<paddle.fluid.dygraph.container.LayerList object at 0x000001F9640FE3A8>\n"
     ]
    }
   ],
   "source": [
    "mm = paddle.nn.LayerList([paddle.nn.Linear(3, 3), \n",
    "                          paddle.nn.ReLU(), \n",
    "                          paddle.nn.Sequential(paddle.nn.Linear(3, 3), paddle.nn.ReLU()), \n",
    "                          paddle.nn.Linear(3, 3)])\n",
    "print(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'-1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-d55bf2d6e1c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\dygraph\\container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msublayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '-1'"
     ]
    }
   ],
   "source": [
    "print(mm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'paddle.fluid.dygraph.container.LayerList'>\n",
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(type(mm[:-1]))\n",
    "print(json.dumps(repr_string(mm[:-1]), indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   },\n",
      "   \"3\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"-1\": \"ReLU()\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "mm[-1] = paddle.nn.ReLU()\n",
    "print(json.dumps(repr_string(mm), indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.LayerList object at 0x000001F9640D9B28>\n",
      "<paddle.fluid.dygraph.container.Sequential object at 0x000001F9640F42E8>\n",
      "<class '__main__.LayerList'>\n",
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   }\n",
      "}\n",
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   },\n",
      "   \"3\": \"ReLU()\"\n",
      "}\n",
      "{\n",
      "   \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "   \"1\": \"ReLU()\",\n",
      "   \"2 (Sequential)\": {\n",
      "      \"0\": \"Linear(input_dim=3, output_dim=3)\",\n",
      "      \"1\": \"ReLU()\"\n",
      "   },\n",
      "   \"3\": \"ReLU()\",\n",
      "   \"4\": \"ReLU()\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class LayerList(paddle.nn.LayerList):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    def _get_abs_string_index(self, idx):\n",
    "        \"\"\"Get the absolute index for the list of modules\"\"\"\n",
    "        idx = operator.index(idx)\n",
    "        if not (-len(self) <= idx < len(self)):\n",
    "            raise IndexError('index {} is out of range'.format(idx))\n",
    "        if idx < 0:\n",
    "            idx += len(self)\n",
    "        return str(idx)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx: Union[slice, int]):\n",
    "        if isinstance(idx, slice):\n",
    "            return self.__class__(list(self._sub_layers.values())[idx])\n",
    "        else:\n",
    "            return self._sub_layers[self._get_abs_string_index(idx)]\n",
    "        \n",
    "    def __setitem__(self, idx: int, layer: paddle.nn.Layer) -> None:\n",
    "        idx = self._get_abs_string_index(idx)\n",
    "        return setattr(self, str(idx), layer)\n",
    "    \n",
    "    T = typing.TypeVar('T')\n",
    "    def __iadd__(self: T, layers: typing.Iterable[paddle.nn.Layer]) -> T:\n",
    "        return self.extend(layers)\n",
    "    \n",
    "    \n",
    "    \n",
    "mm = LayerList([paddle.nn.Linear(3, 3), \n",
    "                  paddle.nn.ReLU(), \n",
    "                  paddle.nn.Sequential(paddle.nn.Linear(3, 3), paddle.nn.ReLU()), \n",
    "                  paddle.nn.Linear(3, 3)])\n",
    "\n",
    "print(mm)\n",
    "print(mm[-2])\n",
    "\n",
    "print(type(mm[:-1]))\n",
    "\n",
    "print(json.dumps(repr_string(mm[:-1]), indent=3))\n",
    "\n",
    "\n",
    "mm[-1] = paddle.nn.ReLU()\n",
    "print(json.dumps(repr_string(mm), indent=3))\n",
    "\n",
    "\n",
    "mm += [paddle.nn.ReLU()]\n",
    "print(json.dumps(repr_string(mm), indent=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModuleDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.ModuleDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.01\n",
      "\n",
      "Parameter Group 1\n",
      "    dampening: 0\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "<torch.optim.lr_scheduler.MultiStepLR object at 0x000001F964062848>\n"
     ]
    }
   ],
   "source": [
    "# param_group\n",
    "\n",
    "mm = torch.nn.Sequential(torch.nn.Linear(3, 3), torch.nn.ReLU(), torch.nn.Linear(3, 3))\n",
    "# optimizer = torch.optim.SGD(params=mm.parameters(), lr=0.1)\n",
    "optimizer = torch.optim.SGD(params=[\n",
    "                                    {'params': mm[0].parameters(), 'lr': 0.01}, \n",
    "                                    {'params': mm[-1].parameters()}], \n",
    "                            lr=0.1, momentum=0.9, weight_decay=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[2, 5], gamma=0.1)\n",
    "\n",
    "print(optimizer)\n",
    "print(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 0.1\n",
      "1 0.001 0.010000000000000002\n",
      "2 0.001 0.010000000000000002\n",
      "3 0.001 0.010000000000000002\n",
      "4 0.0001 0.0010000000000000002\n",
      "5 0.0001 0.0010000000000000002\n",
      "6 0.0001 0.0010000000000000002\n",
      "7 0.0001 0.0010000000000000002\n"
     ]
    }
   ],
   "source": [
    "for e in range(8):\n",
    "    \n",
    "    data = torch.rand(size=(10, 3))\n",
    "    loss = mm(data).sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(e, optimizer.param_groups[0]['lr'], optimizer.param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<paddle.optimizer.sgd.SGD object at 0x000001F9632DCDC8>\n",
      "<paddle.optimizer.lr.MultiStepDecay object at 0x000001F96339AC08>\n"
     ]
    }
   ],
   "source": [
    "mm = paddle.nn.Sequential(paddle.nn.Linear(3, 3), paddle.nn.ReLU(), paddle.nn.Linear(3, 3))\n",
    "\n",
    "parameters = mm.parameters()\n",
    "\n",
    "scheduler1 = paddle.optimizer.lr.MultiStepDecay(learning_rate=0.1, milestones=[2, 5], gamma=0.1)\n",
    "optimizer1 = paddle.optimizer.SGD(learning_rate=scheduler1, \n",
    "                                  parameters=list(mm.children())[0].parameters(), \n",
    "                                  weight_decay=0.01)\n",
    "\n",
    "scheduler2 = paddle.optimizer.lr.MultiStepDecay(learning_rate=0.01, milestones=[2, 5], gamma=0.1)\n",
    "optimizer2 = paddle.optimizer.SGD(learning_rate=scheduler2, \n",
    "                                  parameters=parameters[2:], \n",
    "                                  weight_decay=0.01)\n",
    "\n",
    "print(optimizer1)\n",
    "print(scheduler1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 0.01\n",
      "1 0.010000000000000002 0.001\n",
      "2 0.010000000000000002 0.001\n",
      "3 0.010000000000000002 0.001\n",
      "4 0.0010000000000000002 0.00010000000000000002\n",
      "5 0.0010000000000000002 0.00010000000000000002\n",
      "6 0.0010000000000000002 0.00010000000000000002\n",
      "7 0.0010000000000000002 0.00010000000000000002\n"
     ]
    }
   ],
   "source": [
    "for e in range(8):\n",
    "    \n",
    "    data = paddle.rand(shape=(10, 3))\n",
    "    loss = mm(data).sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer1.step()\n",
    "    optimizer1.clear_grad()\n",
    "    scheduler1.step()\n",
    "    \n",
    "    optimizer2.step()\n",
    "    optimizer2.clear_grad()\n",
    "    scheduler2.step()    \n",
    "    \n",
    "    print(e, optimizer1.get_lr(), optimizer2.get_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python-Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple inheritance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
