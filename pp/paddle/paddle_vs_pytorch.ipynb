{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import paddle\n",
    "import collections\n",
    "import typing\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu101\n",
      "2.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.Module.__repr__\n",
    "# def extra_repr(self) -> str:\n",
    "\n",
    "torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2, padding=1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<paddle.nn.layer.conv.Conv2D object at 0x000001B1455EF828>\n"
     ]
    }
   ],
   "source": [
    "# None\n",
    "mm = paddle.nn.Conv2D(3, 32, kernel_size=(3, 2), stride=2, padding=1)\n",
    "print(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py\n",
    "# \n",
    "\n",
    "# TODO\n",
    "class Layer(paddle.nn.Layer):\n",
    "    def extra_repr(self) -> str:\n",
    "        r\"\"\"Set the extra representation of the module\n",
    "        To print customized extra information, you should re-implement\n",
    "        this method in your own modules. Both single-line and multi-line\n",
    "        strings are acceptable.\n",
    "        \"\"\"\n",
    "        return ''\n",
    "        \n",
    "        \n",
    "class Conv2D(paddle.nn.layer.conv.Conv2D):\n",
    "\n",
    "    def _get_name(self):\n",
    "        return self.__class__.__name__\n",
    "    \n",
    "    def extra_repr(self, ):\n",
    "        s = ('{_in_channels}, {_out_channels}, kernel_size={_kernel_size}'\n",
    "             ', stride={_stride}')\n",
    "        if self._padding != (0,) * len(self._padding):\n",
    "            s += ', padding={_padding}'\n",
    "        if self._dilation != (1,) * len(self._dilation):\n",
    "            s += ', dilation={_dilation}'\n",
    "        if self._groups != 1:\n",
    "            s += ', groups={_groups}'\n",
    "        if self._padding_mode != 'zeros':\n",
    "            s += ', padding_mode={_padding_mode}'\n",
    "        return s.format(**self.__dict__)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # We treat the extra repr like the sub-module, one item per line\n",
    "        extra_lines = []\n",
    "        extra_repr = self.extra_repr()\n",
    "        # empty string will be split into list ['']\n",
    "        if extra_repr:\n",
    "            extra_lines = extra_repr.split('\\n')\n",
    "        child_lines = []\n",
    "        #for key, module in self._modules.items():\n",
    "        #    mod_str = repr(module)\n",
    "        #    mod_str = _addindent(mod_str, 2)\n",
    "        #    child_lines.append('(' + key + '): ' + mod_str)\n",
    "        lines = extra_lines + child_lines\n",
    "\n",
    "        main_str = self._get_name() + '('\n",
    "        if lines:\n",
    "            # simple one-liner info, which most builtin Modules will use\n",
    "            if len(extra_lines) == 1 and not child_lines:\n",
    "                main_str += extra_lines[0]\n",
    "            else:\n",
    "                main_str += '\\n  ' + '\\n  '.join(lines) + '\\n'\n",
    "\n",
    "        main_str += ')'\n",
    "        return main_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2D(3, 32, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], dilation=[1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv2D(in_channels=3, out_channels=32, kernel_size=3, stride=2, padding=1, dilation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "class MM(torch.nn.Module):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, ):\n",
    "        super(MM, self).__init__()\n",
    "        \n",
    "        self.f1 = torch.nn.Linear(10, 10)\n",
    "        self.conv1 = torch.nn.Conv2d(3, 10, 3, 2)\n",
    "        self.seq1 = torch.nn.Sequential(torch.nn.Linear(10, 10), torch.nn.Conv2d(3, 10, 3, 2)) \n",
    "        self.seq2 = torch.nn.Sequential(self.seq1, torch.nn.Conv2d(3, 10, 3, 2))\n",
    "    def forward(self, ):\n",
    "        '''\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MM(\n",
      "  (f1): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (seq1): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (seq2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (1): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      "    )\n",
      "    (1): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(MM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "   \"f1\": \"Linear(input_dim=10, output_dim=10)\",\n",
       "   \"conv1\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\",\n",
       "   \"relu\": \"ReLU()\",\n",
       "   \"seq1\": {\n",
       "      \"0\": \"Linear(input_dim=10, output_dim=10)\",\n",
       "      \"1\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\"\n",
       "   },\n",
       "   \"seq2\": {\n",
       "      \"0\": {\n",
       "         \"0\": \"Linear(input_dim=10, output_dim=10)\",\n",
       "         \"1\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\"\n",
       "      },\n",
       "      \"1\": \"Linear(input_dim=10, output_dim=10)\",\n",
       "      \"2\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\"\n",
       "   },\n",
       "   \"conv2\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\",\n",
       "   \"dropout\": \"Dropout(p=0.5)\"\n",
       "}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "class MM(paddle.nn.Layer):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, ):\n",
    "        super(MM, self).__init__()\n",
    "        \n",
    "        self.f1 = paddle.nn.Linear(10, 10)\n",
    "        self.conv1 = paddle.nn.Conv2D(3, 10, 3, 2)\n",
    "        self.relu = paddle.nn.ReLU()\n",
    "        self.seq1 = paddle.nn.Sequential(paddle.nn.Linear(10, 10), paddle.nn.Conv2D(3, 10, 3, 2)) \n",
    "        self.seq2 = paddle.nn.Sequential(self.seq1, paddle.nn.Linear(10, 10), paddle.nn.Conv2D(3, 10, 3, 2))\n",
    "        self.conv2 = paddle.nn.Conv2D(3, 10, 3, 2)\n",
    "        self.dropout = paddle.nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, ):\n",
    "        '''\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def __repr__(self,):\n",
    "        ''''''\n",
    "        s = repr_string(self)\n",
    "        return json.dumps(repr_string(mm), indent=3)\n",
    "    \n",
    "MM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"f1\": \"Linear(input_dim=10, output_dim=10)\",\n",
      "   \"conv1\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\",\n",
      "   \"relu\": \"ReLU()\",\n",
      "   \"seq1\": {\n",
      "      \"0\": \"Linear(input_dim=10, output_dim=10)\",\n",
      "      \"1\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\"\n",
      "   },\n",
      "   \"seq2\": {\n",
      "      \"0\": {\n",
      "         \"0\": \"Linear(input_dim=10, output_dim=10)\",\n",
      "         \"1\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\"\n",
      "      },\n",
      "      \"1\": \"Linear(input_dim=10, output_dim=10)\",\n",
      "      \"2\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\"\n",
      "   },\n",
      "   \"conv2\": \"Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2), )\",\n",
      "   \"dropout\": \"Dropout(p=0.5)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "mm = MM()\n",
    "# mm = paddle.nn.Sequential(paddle.nn.Linear(10, 10), paddle.nn.Conv2D(3, 10, 3, 2))\n",
    "# mm = paddle.nn.Conv2D(10, 10, 3, 3)\n",
    "\n",
    "def _get_name(layer:paddle.nn.Layer) -> str:\n",
    "    ''''''\n",
    "    return layer.__class__.__name__\n",
    "\n",
    "\n",
    "def repr_string(layer:paddle.nn.Layer) -> str:\n",
    "    ''''''\n",
    "    s = collections.OrderedDict()\n",
    "\n",
    "    if isinstance(layer, paddle.nn.Conv2D):\n",
    "        _s = ''\n",
    "        _s += f'{layer._in_channels}, {layer._out_channels}, '\n",
    "        _s += f'kernel_size={tuple(layer._kernel_size)}, stride={tuple(layer._stride)}, '\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    elif isinstance(layer, paddle.nn.Linear):\n",
    "        _s = ''\n",
    "        _s += f'input_dim={layer.weight.shape[0]}, output_dim={layer.weight.shape[1]}'\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    elif isinstance(layer, paddle.nn.Dropout):\n",
    "        _s = ''\n",
    "        _s += f'p={layer.p}'\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    elif isinstance(layer, paddle.nn.ReLU):\n",
    "        _s = ''\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    elif _get_name(layer) in set(dir(paddle.nn)).difference(set(['Layer', 'Sequential', 'LayerList', 'ParameterList'])):\n",
    "        _s = ''\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    \n",
    "    for _name, _layer in layer.named_children():\n",
    "        # _s = _name\n",
    "        # if isinstance(_layer, (paddle.nn.Sequential, paddle.nn.LayerList, paddle.nn.ParameterList)):\n",
    "        #     _s += f' {_get_name(_layer)}'\n",
    "        s.update({_name: repr_string(_layer)})\n",
    "        \n",
    "    # return {f'{_get_name(layer)}': s}\n",
    "    return s\n",
    "\n",
    "\n",
    "print(json.dumps(repr_string(mm), indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(f1): Linear(input_dim=10, output_dim=10)\n",
      "(conv1): Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      "(seq1):Sequential \n",
      "(\n",
      "(0): Linear(input_dim=10, output_dim=10)\n",
      "(1): Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      ")\n",
      "(seq2):Sequential \n",
      "(\n",
      "(0):Sequential \n",
      "(\n",
      "(0): Linear(input_dim=10, output_dim=10)\n",
      "(1): Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      ")\n",
      "(1): Linear(input_dim=10, output_dim=10)\n",
      "(2): Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      ")\n",
      "(conv2): Conv2D(3, 10, kernel_size=(3, 3), stride=(2, 2))\n"
     ]
    }
   ],
   "source": [
    "mm = MM()\n",
    "\n",
    "def _get_name(layer:paddle.nn.Layer) -> str:\n",
    "    ''''''\n",
    "    return layer.__class__.__name__\n",
    "\n",
    "\n",
    "def repr_string(layer:paddle.nn.Layer) -> str:\n",
    "    ''''''\n",
    "    s = []\n",
    "    \n",
    "    if isinstance(layer, paddle.nn.Conv2D):\n",
    "        _s = ''\n",
    "        _s += f'{layer._in_channels}, {layer._out_channels}, '\n",
    "        _s += f'kernel_size={tuple(layer._kernel_size)}, stride={tuple(layer._stride)}'\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "    if isinstance(layer, paddle.nn.Linear):\n",
    "        _s = ''\n",
    "        _s += f'input_dim={layer.weight.shape[0]}, output_dim={layer.weight.shape[1]}'\n",
    "        return '{}({})'.format(_get_name(layer), _s)\n",
    "    \n",
    "        \n",
    "    for _name, _layer in layer.named_children():\n",
    "        if isinstance(_layer, paddle.nn.Sequential):\n",
    "            _s = '({}):Sequential \\n'.format(_name)\n",
    "            _s += '(\\n{}\\n)'.format(repr_string(_layer))\n",
    "            s.append(_s)  \n",
    "        else:\n",
    "            _s = '({}): '.format(_name)\n",
    "            _s += repr_string(_layer)\n",
    "            s.append(_s)\n",
    "    # print(s)\n",
    "    return '\\n'.join(s)\n",
    "\n",
    "print(repr_string(mm))\n",
    "# json.loads(repr_string(mm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mm = torch.nn.Sequential(torch.nn.Linear(3, 3), torch.nn.ReLU())\n",
    "print(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU()\n"
     ]
    }
   ],
   "source": [
    "print(mm[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mm[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<paddle.fluid.dygraph.container.Sequential object at 0x000001B1456163A8>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'-1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ddd5d763a442>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\paddle\\fluid\\dygraph\\container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '-1'"
     ]
    }
   ],
   "source": [
    "mm = paddle.nn.Sequential(paddle.nn.Linear(3, 3), paddle.nn.ReLU())\n",
    "print(mm)\n",
    "print(mm[-1])\n",
    "print(mm[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ModulList/LayerList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = torch.nn.ModuleList([torch.nn.Linear(3, 3), torch.nn.ReLU()])\n",
    "print(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = paddle.nn.LayerList([paddle.nn.Linear(3, 3), paddle.nn.ReLU()])\n",
    "print(mm)\n",
    "print(mm[-1])\n",
    "print(mm[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_group\n",
    "\n",
    "mm = torch.nn.Sequential(torch.nn.Linear(3, 3), torch.nn.ReLU(), torch.nn.Linear(3, 3))\n",
    "# optimizer = torch.optim.SGD(params=mm.parameters(), lr=0.1)\n",
    "optimizer = torch.optim.SGD(params=[\n",
    "                                    {'params': mm[0].parameters(), 'lr': 0.01}, \n",
    "                                    {'params': mm[-1].parameters()}], \n",
    "                            lr=0.1, momentum=0.9, weight_decay=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[2, 5], gamma=0.1)\n",
    "\n",
    "print(optimizer)\n",
    "print(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(8):\n",
    "    \n",
    "    data = torch.rand(size=(10, 3))\n",
    "    loss = mm(data).sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(e, optimizer.param_groups[0]['lr'], optimizer.param_groups[1]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = paddle.nn.Sequential(paddle.nn.Linear(3, 3), paddle.nn.ReLU(), paddle.nn.Linear(3, 3))\n",
    "\n",
    "parameters = mm.parameters()\n",
    "\n",
    "scheduler1 = paddle.optimizer.lr.MultiStepDecay(learning_rate=0.1, milestones=[2, 5], gamma=0.1)\n",
    "optimizer1 = paddle.optimizer.SGD(learning_rate=scheduler1, \n",
    "                                  parameters=list(mm.children())[0].parameters(), \n",
    "                                  weight_decay=0.01)\n",
    "\n",
    "scheduler2 = paddle.optimizer.lr.MultiStepDecay(learning_rate=0.01, milestones=[2, 5], gamma=0.1)\n",
    "optimizer2 = paddle.optimizer.SGD(learning_rate=scheduler2, \n",
    "                                  parameters=parameters[2:], \n",
    "                                  weight_decay=0.01)\n",
    "\n",
    "print(optimizer1)\n",
    "print(scheduler1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(8):\n",
    "    \n",
    "    data = paddle.rand(shape=(10, 3))\n",
    "    loss = mm(data).sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer1.step()\n",
    "    optimizer1.clear_grad()\n",
    "    scheduler1.step()\n",
    "    \n",
    "    optimizer2.step()\n",
    "    optimizer2.clear_grad()\n",
    "    scheduler2.step()    \n",
    "    \n",
    "    print(e, optimizer1.get_lr(), optimizer2.get_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
