{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "# https://github.com/Lyken17/pytorch-OpCounter/tree/master/thop\n",
    "# https://arxiv.org/pdf/1611.06440.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = paddle.vision.models.resnet34()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "   Layer (type)         Input Shape          Output Shape         Param #    \n",
      "===============================================================================\n",
      "    Conv2D-217       [[1, 3, 224, 224]]   [1, 64, 112, 112]        9,408     \n",
      "  BatchNorm2D-217   [[1, 64, 112, 112]]   [1, 64, 112, 112]         256      \n",
      "     ReLU-103       [[1, 64, 112, 112]]   [1, 64, 112, 112]          0       \n",
      "    MaxPool2D-7     [[1, 64, 112, 112]]    [1, 64, 56, 56]           0       \n",
      "    Conv2D-218       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "  BatchNorm2D-218    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "     ReLU-104        [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "    Conv2D-219       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "  BatchNorm2D-219    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "   BasicBlock-97     [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "    Conv2D-220       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "  BatchNorm2D-220    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "     ReLU-105        [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "    Conv2D-221       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "  BatchNorm2D-221    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "   BasicBlock-98     [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "    Conv2D-222       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "  BatchNorm2D-222    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "     ReLU-106        [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "    Conv2D-223       [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \n",
      "  BatchNorm2D-223    [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \n",
      "   BasicBlock-99     [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "    Conv2D-225       [[1, 64, 56, 56]]     [1, 128, 28, 28]       73,728     \n",
      "  BatchNorm2D-225    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "     ReLU-107        [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Conv2D-226       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-226    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "    Conv2D-224       [[1, 64, 56, 56]]     [1, 128, 28, 28]        8,192     \n",
      "  BatchNorm2D-224    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "  BasicBlock-100     [[1, 64, 56, 56]]     [1, 128, 28, 28]          0       \n",
      "    Conv2D-227       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-227    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "     ReLU-108        [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Conv2D-228       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-228    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "  BasicBlock-101     [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Conv2D-229       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-229    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "     ReLU-109        [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Conv2D-230       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-230    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "  BasicBlock-102     [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Conv2D-231       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-231    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "     ReLU-110        [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Conv2D-232       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \n",
      "  BatchNorm2D-232    [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \n",
      "  BasicBlock-103     [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Conv2D-234       [[1, 128, 28, 28]]    [1, 256, 14, 14]       294,912    \n",
      "  BatchNorm2D-234    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "     ReLU-111        [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-235       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-235    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "    Conv2D-233       [[1, 128, 28, 28]]    [1, 256, 14, 14]       32,768     \n",
      "  BatchNorm2D-233    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "  BasicBlock-104     [[1, 128, 28, 28]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-236       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-236    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "     ReLU-112        [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-237       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-237    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "  BasicBlock-105     [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-238       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-238    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "     ReLU-113        [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-239       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-239    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "  BasicBlock-106     [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-240       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-240    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "     ReLU-114        [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-241       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-241    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "  BasicBlock-107     [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-242       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-242    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "     ReLU-115        [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-243       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-243    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "  BasicBlock-108     [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-244       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-244    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "     ReLU-116        [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-245       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \n",
      "  BatchNorm2D-245    [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \n",
      "  BasicBlock-109     [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \n",
      "    Conv2D-247       [[1, 256, 14, 14]]     [1, 512, 7, 7]       1,179,648   \n",
      "  BatchNorm2D-247     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "     ReLU-117         [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "    Conv2D-248        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-248     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "    Conv2D-246       [[1, 256, 14, 14]]     [1, 512, 7, 7]        131,072    \n",
      "  BatchNorm2D-246     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "  BasicBlock-110     [[1, 256, 14, 14]]     [1, 512, 7, 7]           0       \n",
      "    Conv2D-249        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-249     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "     ReLU-118         [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "    Conv2D-250        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-250     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "  BasicBlock-111      [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "    Conv2D-251        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-251     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "     ReLU-119         [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "    Conv2D-252        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \n",
      "  BatchNorm2D-252     [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \n",
      "  BasicBlock-112      [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "AdaptiveAvgPool2D-7   [[1, 512, 7, 7]]      [1, 512, 1, 1]           0       \n",
      "     Linear-8            [[1, 512]]           [1, 1000]           513,000    \n",
      "===============================================================================\n",
      "Total params: 21,814,696\n",
      "Trainable params: 21,780,648\n",
      "Non-trainable params: 34,048\n",
      "-------------------------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 85.76\n",
      "Params size (MB): 83.22\n",
      "Estimated Total Size (MB): 169.55\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 21814696, 'trainable_params': 21780648}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddle.summary(model, (1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "totle_num = 0\n",
    "\n",
    "def _conv2d_hook(layer, inputs, output):\n",
    "    '''\n",
    "    '''\n",
    "    o = output.shape[0] * output.shape[2] * output.shape[2]   \n",
    "    k = layer.weight.numel() \n",
    "    b = 1 if layer.bias is not None else 0\n",
    "    \n",
    "    layer.op_num += o * (k + b)\n",
    "\n",
    "\n",
    "def _relu_hook(layer, inputs, output):\n",
    "    '''\n",
    "    '''\n",
    "    layer.op_num += inputs[0].numel()\n",
    "    \n",
    "\n",
    "def _linear_hook(layer, inputs, output):\n",
    "    '''\n",
    "    '''\n",
    "    in_channels = layer.weight.shape[0]    \n",
    "    layer.op_num += in_channels * output.numel()\n",
    "\n",
    "\n",
    "hooks = {\n",
    "    paddle.nn.Conv2D : _conv2d_hook,\n",
    "    paddle.nn.ReLU : _relu_hook,\n",
    "    paddle.nn.Linear : _linear_hook,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def register_hook(model):\n",
    "    \n",
    "    for m in model.sublayers():\n",
    "        if type(m) in hooks:\n",
    "            m.register_forward_post_hook( hooks[type(m)] )\n",
    "            m.register_buffer('op_num', paddle.zeros(shape=(1, ), dtype='float32'))\n",
    "            \n",
    "    print('register done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "register done...\n"
     ]
    }
   ],
   "source": [
    "register_hook(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1000]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(paddle.rand((1, 3, 224, 224))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW) 118013950.0\n",
      "2 ReLU() 802816.0\n",
      "6 Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "8 ReLU() 401408.0\n",
      "9 Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "12 Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "14 ReLU() 401408.0\n",
      "15 Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "18 Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "20 ReLU() 401408.0\n",
      "21 Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "25 Conv2D(64, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW) 57802750.0\n",
      "27 ReLU() 200704.0\n",
      "28 Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "31 Conv2D(64, 128, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW) 6422528.0\n",
      "34 Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "36 ReLU() 200704.0\n",
      "37 Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "40 Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "42 ReLU() 200704.0\n",
      "43 Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "46 Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "48 ReLU() 200704.0\n",
      "49 Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "53 Conv2D(128, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW) 57802750.0\n",
      "55 ReLU() 100352.0\n",
      "56 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "59 Conv2D(128, 256, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW) 6422528.0\n",
      "62 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "64 ReLU() 100352.0\n",
      "65 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "68 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "70 ReLU() 100352.0\n",
      "71 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "74 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "76 ReLU() 100352.0\n",
      "77 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "80 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "82 ReLU() 100352.0\n",
      "83 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "86 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "88 ReLU() 100352.0\n",
      "89 Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "93 Conv2D(256, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW) 57802750.0\n",
      "95 ReLU() 50176.0\n",
      "96 Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "99 Conv2D(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW) 6422528.0\n",
      "102 Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "104 ReLU() 50176.0\n",
      "105 Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "108 Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "110 ReLU() 50176.0\n",
      "111 Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW) 115605500.0\n",
      "114 Linear(in_features=512, out_features=1000, dtype=float32) 512000.0\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(model.sublayers()):\n",
    "    if hasattr(m, 'op_num'):\n",
    "        print(i, m, m.op_num.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
