
model_file: "./pp_model.prototxt"


dataloader {
    batch_size: 32
    num_workers: 8
    shuffle: true
}


optimizer {
    name: "optimizer"
    type: "SGD"
    
    lr: 0.1
    momentum: 0.3
    
    params_group {
        lr: 0.01
        momentum: 0.2
        # params_inline: "params_1 = [p for n, p in self.model.named_parameters() if 'weight' in n]"
        params_inline: "params_1 = [p for n, p in model.named_parameters() if 'weight' in n]"
    }
    params_group {
        lr: 0.1
        params_inline: "params_2 = [p for n, p in model.named_parameters() if not 'weight' in n]"
    }
    
    # module_file: "./pp_optimizer.py.txt"
}


lr_scheduler {
    name: "lr_scheduler"
    
    type: "MultiStepLR"
    gamma: 0.1
    milestones: [10, 20]
    
    # module_inline: "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1, 2], gamma=0.1)"
}
    

epoches: 5
snapshot: 10




# optimizer {
#     code:"\n"
#         "import torch \n"
#         "print('---optmizer-----') \n"
#         "def optimizer(model, lr): \n"
#         "    return torch.optim.SGD(model.parameters(), lr=lr) \n"
#         "\n"
# }


# model {
#     name: "model"
#     
#     module {
#       name: "conv1"
#       type: "Conv2d"
#       bottom: "data"
#       top: "conv1"
#       conv2d_param {
#         in_channels: 20
#         out_channels: 5
#         kernel_size: 3
#       }
#       phase: 1
#     }
#     
#     module {
#       name: "resnet"
#       type: "ResNet"
#       bottom: "conv1"
#       top: "resnet1"
#       resnet_param {
#         layers: "34"
#       }
#     }
#      
# }
