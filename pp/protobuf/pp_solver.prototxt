
model_file: "./pp_model.prototxt"


dataset {
    name: "dummydataset"
    phase: 1
    type: "DummyDataset"
    
    top: "data"
    top: "label"
    
    dummydataset_param {
        n: 10
    }
}


dataloader {
    batch_size: 32
    num_workers: 8
    shuffle: true
}


optimizer {
    name: "optimizer"
    
    type: "SGD"
    lr: 0.1
    momentum: 0.3
    
    params_group {
        lr: 0.01
        momentum: 0.2
        # params_inline: "params_1 = [p for n, p in self.model.named_parameters() if 'weight' in n]"
        params_inline: "params_1 = [p for n, p in model.named_parameters() if 'weight' in n]"
    }
    params_group {
        lr: 0.1
        params_inline: "params_2 = [p for n, p in model.named_parameters() if not 'weight' in n]"
    }
    
    # module_file: "./pp_optimizer.py.txt"
    
}


lr_scheduler {
    name: "lr_scheduler_1"
    type: "MultiStepLR"
    gamma: 0.1
    milestones: [10, 20]
    
    # module_inline: "lr_scheduler_1 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1, 2], gamma=0.1)"
}
    

device: "cpu"


#distributed {
#    backend: "nccl"
#    init_method: "env://"
#    world_size: 4
#}


epoches: 3

snapshot: 10
log_dir: "./logs"
prefix: "pp_model"



# optimizer {
#     code:"\n"
#         "import torch \n"
#         "print('---optmizer-----') \n"
#         "def optimizer(model, lr): \n"
#         "    return torch.optim.SGD(model.parameters(), lr=lr) \n"
#         "\n"
# }


# model {
#     name: "model"
#     
#     module {
#       name: "conv1"
#       type: "Conv2d"
#       bottom: "data"
#       top: "conv1"
#       conv2d_param {
#         in_channels: 20
#         out_channels: 5
#         kernel_size: 3
#       }
#       phase: 1
#     }
#     
#     module {
#       name: "resnet"
#       type: "ResNet"
#       bottom: "conv1"
#       top: "resnet1"
#       resnet_param {
#         layers: "34"
#       }
#     }
#      
# }
