

## Transformer
- [Intriguing Properties of Vision Transformers](https://arxiv.org/abs/2105.10497)


## Generation
### Diffusion
- https://lilianweng.github.io/posts/2021-07-11-diffusion-models/
- https://github.com/zoubohao/DenoisingDiffusionProbabilityModel-ddpm-/
- [Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239.pdf)
- [Hierarchical Text-Conditional Image Generation with CLIP Latents](https://arxiv.org/pdf/2204.06125.pdf)
- [High-Resolution Image Synthesis with Latent Diffusion Models](https://github.com/CompVis/stable-diffusion)
- [Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation]()
- [An image is worth one word: Personalizing text-to-image generation using textual inversion]()
- [Pivotal tuning for latent-based editing of real images]()

### GAN
- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)

### Consistency Models
- [Consistency Models](https://arxiv.org/pdf/2303.01469v1.pdf)


## CV
- [Segment Anything](https://arxiv.org/pdf/2304.02643.pdf)
- [Inpaint Anything: Segment Anything Meets Image Inpainting](https://arxiv.org/pdf/2304.06790.pdf)
- [LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions](https://github.com/geekyutao/Inpaint-Anything/tree/main/lama)


## Multimodality
- [Multimodality Helps Unimodality: Cross-Modal Few-Shot Learning with Multimodal Models]()
- [Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection](https://arxiv.org/pdf/2303.05499v4.pdf)


## Prompt 
- [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf)
- [The Prompt Artists](https://arxiv.org/pdf/2303.12253.pdf)


## PEFT
- [State-of-the-art Parameter-Efficient Fine-Tuning (PEFT) methods](https://github.com/huggingface/peft)
- [LoRA: Low-Rank Adaption of Large Language Models](https://arxiv.org/pdf/2106.09685.pdf)
